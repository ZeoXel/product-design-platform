#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆå›¾åº“ä¸Šä¼ è„šæœ¬
- è‡ªåŠ¨å‹ç¼©å›¾ç‰‡
- ä½¿ç”¨æ¨¡æ‹Ÿåˆ†ææ•°æ®
- ç”ŸæˆåµŒå…¥å‘é‡ç”¨äºç›¸ä¼¼åº¦æ£€ç´¢
"""
import os
import sys
import asyncio
import base64
import uuid
import json
from pathlib import Path
from datetime import datetime
from PIL import Image
import io

# æ·»åŠ  backend ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from services.embedding_service import embedding_service
from models import ImageAnalysis, ElementsGroup, StyleInfo, PhysicalSpecs
import numpy as np


def compress_image(image_path: Path, max_size_kb: int = 500) -> bytes:
    """å‹ç¼©å›¾ç‰‡åˆ°æŒ‡å®šå¤§å°"""
    img = Image.open(image_path)

    # è½¬æ¢ä¸º RGB
    if img.mode in ('RGBA', 'P', 'LA'):
        img = img.convert('RGB')

    # è®¡ç®—ç¼©æ”¾æ¯”ä¾‹
    max_dimension = 1024
    if max(img.size) > max_dimension:
        ratio = max_dimension / max(img.size)
        new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))
        img = img.resize(new_size, Image.Resampling.LANCZOS)

    # å‹ç¼©ä¸º JPEG
    quality = 85
    while True:
        buffer = io.BytesIO()
        img.save(buffer, format='JPEG', quality=quality, optimize=True)
        data = buffer.getvalue()

        if len(data) <= max_size_kb * 1024 or quality <= 30:
            return data

        quality -= 10


def create_mock_analysis(filename: str) -> ImageAnalysis:
    """åˆ›å»ºæ¨¡æ‹Ÿåˆ†ææ•°æ®"""
    # æ ¹æ®æ–‡ä»¶åç”Ÿæˆä¸åŒçš„å…ƒç´ 
    elements = {
        "primary": [
            {"type": "è´å£³", "color": "ç±³ç™½è‰²"},
            {"type": "çç ", "color": "ç™½è‰²"}
        ],
        "secondary": [
            {"type": "å°ç å­", "count": 8}
        ],
        "hardware": [
            {"type": "é‡‘å±æ‰£", "material": "åˆé‡‘"}
        ]
    }

    return ImageAnalysis(
        elements=ElementsGroup(**elements),
        style=StyleInfo(
            tags=["æ‰‹å·¥", "è‡ªç„¶", "ç®€çº¦"],
            mood="æ¸…æ–°è‡ªç„¶"
        ),
        physicalSpecs=PhysicalSpecs(
            lengthCm=15.0,
            weightG=12.0
        ),
        suggestions=["å¯ä»¥å°è¯•ä¸åŒçš„é…è‰²æ–¹æ¡ˆ"]
    )


async def upload_images():
    """æ‰¹é‡ä¸Šä¼ å›¾ç‰‡"""
    images_dir = Path(__file__).parent.parent / "data" / "gallery" / "images"
    embeddings_dir = Path(__file__).parent.parent / "data" / "gallery" / "embeddings"
    metadata_file = Path(__file__).parent.parent / "data" / "gallery" / "metadata.json"

    # åŠ è½½ç°æœ‰å…ƒæ•°æ®
    if metadata_file.exists():
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
    else:
        metadata = {"items": []}

    # è·å–æ‰€æœ‰ PNG å›¾ç‰‡
    image_files = [
        f for f in images_dir.iterdir()
        if f.is_file() and f.suffix.lower() == '.png'
        and f.name.startswith('æˆªå±')
    ]

    print(f"ğŸ“ æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print("=" * 60)

    success_count = 0
    failed_count = 0

    for i, image_file in enumerate(image_files, 1):
        print(f"\n[{i}/{len(image_files)}] {image_file.name}")

        try:
            # å‹ç¼©å›¾ç‰‡
            print(f"  ğŸ—œï¸  å‹ç¼©å›¾ç‰‡...")
            compressed_data = compress_image(image_file, max_size_kb=400)
            print(f"  âœ“ å‹ç¼©å®Œæˆ: {len(compressed_data) / 1024:.1f} KB")

            # è½¬æ¢ä¸º base64
            image_base64 = base64.b64encode(compressed_data).decode('utf-8')

            # ç”Ÿæˆæ–° ID
            ref_id = str(uuid.uuid4())

            # ä¿å­˜å‹ç¼©åçš„å›¾ç‰‡ï¼ˆè¦†ç›–åŸå›¾ï¼‰
            jpg_filename = f"{ref_id}.jpg"
            jpg_path = images_dir / jpg_filename

            with open(jpg_path, 'wb') as f:
                f.write(compressed_data)

            print(f"  ğŸ’¾ ä¿å­˜ä¸º: {jpg_filename}")

            # åˆ›å»ºæ¨¡æ‹Ÿåˆ†æ
            analysis = create_mock_analysis(image_file.name)

            # ç”Ÿæˆæ–‡æœ¬æè¿°ç”¨äºåµŒå…¥
            text_description = f"{' '.join(analysis.style.tags)} {analysis.style.mood}"

            # ç”ŸæˆåµŒå…¥å‘é‡ï¼ˆåŸºäºæ–‡æœ¬æè¿°ï¼‰
            print(f"  ğŸ§® ç”ŸæˆåµŒå…¥å‘é‡...")
            try:
                embedding = await embedding_service.generate_embedding(
                    image_base64=image_base64,
                    text=text_description
                )

                # åªæœ‰æˆåŠŸç”ŸæˆåµŒå…¥æ—¶æ‰ä¿å­˜
                if embedding is not None:
                    embedding_path = embeddings_dir / f"{ref_id}.npy"
                    np.save(embedding_path, embedding)
                    print(f"  âœ“ åµŒå…¥å‘é‡å·²ä¿å­˜")
                else:
                    print(f"  âš ï¸  è·³è¿‡åµŒå…¥å‘é‡ç”Ÿæˆï¼ˆç¨åå¯é€šè¿‡å‰ç«¯é‡æ–°ç”Ÿæˆï¼‰")
            except Exception as emb_error:
                print(f"  âš ï¸  åµŒå…¥å‘é‡ç”Ÿæˆå¤±è´¥: {emb_error}")
                print(f"  âš ï¸  è·³è¿‡åµŒå…¥å‘é‡ï¼Œç»§ç»­å¤„ç†...")

            # æ·»åŠ åˆ°å…ƒæ•°æ®
            item = {
                "id": ref_id,
                "filename": jpg_filename,
                "uploadTime": datetime.now().isoformat(),
                "analysis": analysis.model_dump(),
                "salesTier": "B"
            }

            metadata["items"].append(item)

            # ä¿å­˜å…ƒæ•°æ®
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)

            print(f"  âœ… æˆåŠŸ: {ref_id}")
            success_count += 1

            # åˆ é™¤åŸå§‹ PNG æ–‡ä»¶
            # image_file.unlink()

        except Exception as e:
            print(f"  âŒ å¤±è´¥: {str(e)}")
            failed_count += 1
            import traceback
            traceback.print_exc()

    print("\n" + "=" * 60)
    print(f"ğŸ“Š ä¸Šä¼ å®Œæˆ")
    print(f"  âœ… æˆåŠŸ: {success_count}")
    print(f"  âŒ å¤±è´¥: {failed_count}")
    print(f"  ğŸ“ æ€»è®¡: {len(image_files)}")


if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æ‰¹é‡ä¸Šä¼ å›¾åº“ç´ æï¼ˆç®€åŒ–ç‰ˆï¼‰...")
    asyncio.run(upload_images())
