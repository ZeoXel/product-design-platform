#!/usr/bin/env python3
"""
é‡æ–°ç”Ÿæˆå›¾åº“ä¸­æ‰€æœ‰å›¾ç‰‡çš„åµŒå…¥å‘é‡
ä½¿ç”¨æ”¹è¿›çš„æ ‡å‡†åŒ–æè¿°æ–¹æ³•
"""
import asyncio
import json
import sys
from pathlib import Path
import numpy as np

# æ·»åŠ  backend ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from models import ImageAnalysis
from services.embedding_service import embedding_service
from services.search_utils import generate_multimodal_search_description


async def regenerate_embeddings():
    """é‡æ–°ç”Ÿæˆæ‰€æœ‰åµŒå…¥å‘é‡"""
    # è·¯å¾„è®¾ç½®
    base_dir = Path(__file__).parent.parent / "data" / "gallery"
    embeddings_dir = base_dir / "embeddings"
    metadata_file = base_dir / "metadata.json"

    if not metadata_file.exists():
        print("âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return

    # åŠ è½½å…ƒæ•°æ®
    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    items = metadata.get("items", [])
    total = len(items)

    if total == 0:
        print("âš ï¸  å›¾åº“ä¸­æ²¡æœ‰å›¾ç‰‡")
        return

    print("\n" + "="*60)
    print(f"ğŸ“Š å›¾åº“åµŒå…¥å‘é‡é‡æ–°ç”Ÿæˆ")
    print("="*60)
    print(f"\næ€»å…±éœ€è¦å¤„ç† {total} å¼ å›¾ç‰‡")
    print(f"ä½¿ç”¨æ”¹è¿›çš„æ ‡å‡†åŒ–æè¿°æ–¹æ³•\n")

    # ç»Ÿè®¡
    success_count = 0
    skipped_count = 0
    error_count = 0

    # å¤„ç†æ¯ä¸ªé¡¹ç›®
    for idx, item in enumerate(items, 1):
        ref_id = item["id"]
        print(f"\n[{idx}/{total}] å¤„ç† {ref_id}...")

        try:
            # ä»å…ƒæ•°æ®ä¸­è·å–åˆ†æç»“æœ
            analysis_dict = item.get("analysis")
            if not analysis_dict:
                print(f"  âš ï¸  è·³è¿‡ï¼šæ— åˆ†ææ•°æ®")
                skipped_count += 1
                continue

            # è½¬æ¢ä¸º ImageAnalysis å¯¹è±¡
            try:
                analysis = ImageAnalysis(**analysis_dict)
            except Exception as e:
                print(f"  âš ï¸  è·³è¿‡ï¼šåˆ†ææ•°æ®æ ¼å¼é”™è¯¯ - {e}")
                skipped_count += 1
                continue

            # ç”Ÿæˆæ ‡å‡†åŒ–æè¿°
            text_desc = generate_multimodal_search_description(analysis)
            print(f"  ğŸ“ æè¿°: {text_desc[:80]}...")

            # ç”ŸæˆåµŒå…¥å‘é‡
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªä½¿ç”¨æ–‡æœ¬ï¼Œå› ä¸ºå›¾ç‰‡æ–‡ä»¶å¯èƒ½ä¸å­˜åœ¨æˆ–å¤ªå¤§
            embedding = await embedding_service.generate_embedding(
                image_base64="",  # ä¸ä½¿ç”¨å›¾åƒ
                text=text_desc
            )

            if embedding is not None:
                # ä¿å­˜å‘é‡
                embedding_path = embeddings_dir / f"{ref_id}.npy"
                np.save(embedding_path, embedding)
                print(f"  âœ… å‘é‡å·²ç”Ÿæˆå¹¶ä¿å­˜ ({embedding.shape})")
                success_count += 1
            else:
                print(f"  âŒ å‘é‡ç”Ÿæˆå¤±è´¥")
                error_count += 1

        except Exception as e:
            print(f"  âŒ å¤„ç†å¤±è´¥: {e}")
            error_count += 1
            import traceback
            traceback.print_exc()

        # é¿å…è¯·æ±‚è¿‡å¿«
        if idx < total:
            await asyncio.sleep(0.5)

    # æ‰“å°ç»Ÿè®¡
    print("\n" + "="*60)
    print("ğŸ“Š å¤„ç†å®Œæˆ")
    print("="*60)
    print(f"âœ… æˆåŠŸ: {success_count}")
    print(f"âš ï¸  è·³è¿‡: {skipped_count}")
    print(f"âŒ å¤±è´¥: {error_count}")
    print(f"ğŸ“Š æ€»è®¡: {total}")
    print()

    if success_count > 0:
        print(f"ğŸ‰ å·²æˆåŠŸé‡æ–°ç”Ÿæˆ {success_count} ä¸ªåµŒå…¥å‘é‡")
        print("   ä½¿ç”¨æ–°çš„æ ‡å‡†åŒ–æè¿°æ–¹æ³•ï¼Œæ£€ç´¢å‡†ç¡®åº¦å°†å¾—åˆ°æå‡")
    else:
        print("âš ï¸  æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•å‘é‡ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")


async def verify_embeddings():
    """éªŒè¯åµŒå…¥å‘é‡æ˜¯å¦æ­£ç¡®ç”Ÿæˆ"""
    base_dir = Path(__file__).parent.parent / "data" / "gallery"
    embeddings_dir = base_dir / "embeddings"
    metadata_file = base_dir / "metadata.json"

    if not metadata_file.exists():
        print("âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
        return

    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    items = metadata.get("items", [])

    print("\n" + "="*60)
    print("ğŸ” éªŒè¯åµŒå…¥å‘é‡")
    print("="*60)

    total = len(items)
    has_embedding = 0
    missing_embedding = []

    for item in items:
        ref_id = item["id"]
        embedding_path = embeddings_dir / f"{ref_id}.npy"

        if embedding_path.exists():
            # éªŒè¯å‘é‡å¯ä»¥è¢«åŠ è½½
            try:
                emb = np.load(embedding_path)
                print(f"âœ… {ref_id}: shape={emb.shape}, norm={np.linalg.norm(emb):.4f}")
                has_embedding += 1
            except Exception as e:
                print(f"âŒ {ref_id}: æ— æ³•åŠ è½½ - {e}")
                missing_embedding.append(ref_id)
        else:
            print(f"âš ï¸  {ref_id}: å‘é‡æ–‡ä»¶ä¸å­˜åœ¨")
            missing_embedding.append(ref_id)

    print("\n" + "="*60)
    print(f"æ€»è®¡: {total}")
    print(f"æœ‰å‘é‡: {has_embedding}")
    print(f"ç¼ºå¤±: {len(missing_embedding)}")

    if missing_embedding:
        print(f"\nç¼ºå¤±å‘é‡çš„é¡¹ç›®:")
        for ref_id in missing_embedding:
            print(f"  - {ref_id}")


async def test_similarity():
    """æµ‹è¯•ç›¸ä¼¼åº¦æ£€ç´¢"""
    from services.gallery_service import gallery_service

    print("\n" + "="*60)
    print("ğŸ” æµ‹è¯•ç›¸ä¼¼åº¦æ£€ç´¢")
    print("="*60)

    # è¯»å–ç¬¬ä¸€å¼ å›¾ç‰‡çš„å‘é‡ä½œä¸ºæŸ¥è¯¢
    base_dir = Path(__file__).parent.parent / "data" / "gallery"
    embeddings_dir = base_dir / "embeddings"
    metadata_file = base_dir / "metadata.json"

    with open(metadata_file, 'r', encoding='utf-8') as f:
        metadata = json.load(f)

    items = metadata.get("items", [])
    if not items:
        print("âš ï¸  å›¾åº“ä¸ºç©º")
        return

    # ä½¿ç”¨ç¬¬ä¸€ä¸ªé¡¹ç›®ä½œä¸ºæŸ¥è¯¢
    test_item = items[0]
    test_id = test_item["id"]
    embedding_path = embeddings_dir / f"{test_id}.npy"

    if not embedding_path.exists():
        print(f"âŒ æµ‹è¯•é¡¹ç›® {test_id} æ²¡æœ‰å‘é‡")
        return

    query_embedding = np.load(embedding_path)
    print(f"\nğŸ“ æŸ¥è¯¢å›¾ç‰‡: {test_id}")

    # ä»åˆ†æä¸­æå–ä¿¡æ¯
    analysis_dict = test_item.get("analysis", {})
    style = analysis_dict.get("style", {})
    print(f"   é£æ ¼: {', '.join(style.get('tags', []))}")

    # æ‰§è¡Œæ£€ç´¢
    results = await gallery_service.find_similar(query_embedding, top_k=5, threshold=0.0)

    print(f"\nğŸ¯ æ‰¾åˆ° {len(results)} ä¸ªç›¸ä¼¼ç»“æœ:\n")
    for i, result in enumerate(results, 1):
        item_analysis = result["item"].get("analysis", {})
        item_style = item_analysis.get("style", {})
        similarity = result["similarity"]

        print(f"{i}. {result['id']}")
        print(f"   ç›¸ä¼¼åº¦: {similarity:.2%}")
        print(f"   é£æ ¼: {', '.join(item_style.get('tags', []))}")
        print()


if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1:
        if sys.argv[1] == "--verify":
            asyncio.run(verify_embeddings())
        elif sys.argv[1] == "--test":
            asyncio.run(test_similarity())
        else:
            print("ç”¨æ³•:")
            print("  python regenerate_embeddings.py           # é‡æ–°ç”Ÿæˆæ‰€æœ‰å‘é‡")
            print("  python regenerate_embeddings.py --verify  # éªŒè¯å‘é‡å®Œæ•´æ€§")
            print("  python regenerate_embeddings.py --test    # æµ‹è¯•ç›¸ä¼¼åº¦æ£€ç´¢")
    else:
        asyncio.run(regenerate_embeddings())
